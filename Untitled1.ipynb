{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aa34ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# internal imports\n",
    "from wsi_core.WholeSlideImage import WholeSlideImage \n",
    "from wsi_core.wsi_utils import StitchPatches\n",
    "from wsi_core.batch_process_utils import initialize_df\n",
    "# other imports\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import pdb\n",
    "import pandas as pd\n",
    "\n",
    "def stitching(file_path, downscale = 64):\n",
    "    start = time.time()\n",
    "\theatmap = StitchPatches(file_path, downscale=downscale, bg_color=(0,0,0), alpha=-1, draw_grid=False)\n",
    "\ttotal_time = time.time() - start\n",
    "\t\n",
    "\treturn heatmap, total_time\n",
    "\n",
    "def segment(WSI_object, seg_params, filter_params):\n",
    "\t### Start Seg Timer\n",
    "\tstart_time = time.time()\n",
    "\n",
    "\t# Segment\n",
    "\tWSI_object.segmentTissue(**seg_params, filter_params=filter_params)\n",
    "\n",
    "\t### Stop Seg Timers\n",
    "\tseg_time_elapsed = time.time() - start_time   \n",
    "\treturn WSI_object, seg_time_elapsed\n",
    "\n",
    "def patching(WSI_object, **kwargs):\n",
    "\t### Start Patch Timer\n",
    "\tstart_time = time.time()\n",
    "\n",
    "\t# Patch\n",
    "\tfile_path = WSI_object.createPatches_bag_hdf5(**kwargs, save_coord=True)\n",
    "\n",
    "\t### Stop Patch Timer\n",
    "\tpatch_time_elapsed = time.time() - start_time\n",
    "\treturn file_path, patch_time_elapsed\n",
    "\n",
    "def seg_and_patch(source, save_dir, patch_save_dir, mask_save_dir, stitch_save_dir, \n",
    "\t\t\t\t  patch_size = 256, step_size = 256, custom_downsample=1, \n",
    "\t\t\t\t  seg_params = {'seg_level': -1, 'sthresh': 8, 'mthresh': 7, 'close': 4, 'use_otsu': False,\n",
    "\t\t\t\t  'keep_ids': 'none', 'exclude_ids': 'none'},\n",
    "\t\t\t\t  filter_params = {'a_t':100, 'a_h': 16, 'max_n_holes':8 }, \n",
    "\t\t\t\t  vis_params = {'vis_level': -1, 'line_thickness': 250},\n",
    "\t\t\t\t  patch_params = {'white_thresh': 5, 'black_thresh': 40, 'use_padding': True, 'contour_fn': 'four_pt'},\n",
    "\t\t\t\t  patch_level = 0,\n",
    "\t\t\t\t  use_default_params = False, \n",
    "\t\t\t\t  seg = False, save_mask = True, \n",
    "\t\t\t\t  stitch= False, \n",
    "\t\t\t\t  patch = False, auto_skip=True, process_list = None):\n",
    "\t\n",
    "\n",
    "\n",
    "\tslides = sorted(os.listdir(source))\n",
    "\tslides = [slide for slide in slides if os.path.isfile(os.path.join(source, slide))]\n",
    "\n",
    "\tif process_list is None:\n",
    "\t\tdf = initialize_df(slides, seg_params, filter_params, vis_params, patch_params, save_patches=True)\n",
    "\t\n",
    "\telse:\n",
    "\t\tdf = pd.read_csv(process_list)\n",
    "\t\tdf = initialize_df(df, seg_params, filter_params, vis_params, patch_params, save_patches=True)\n",
    "\n",
    "\n",
    "\tmask = df['process'] == 1\n",
    "\tprocess_stack = df[mask]\n",
    "\n",
    "\ttotal = len(process_stack)\n",
    "\tseg_times = 0.\n",
    "\tpatch_times = 0.\n",
    "\tstitch_times = 0.\n",
    "\n",
    "\tfor i in range(total):\n",
    "\t\tdf.to_csv(os.path.join(save_dir, 'process_list_autogen.csv'), index=False)\n",
    "\t\tidx = process_stack.index[i]\n",
    "\t\tslide = process_stack.loc[idx, 'slide_id']\n",
    "\t\tprint(\"\\n\\nprogress: {:.2f}, {}/{}\".format(i/total, i, total))\n",
    "\t\tprint('processing {}'.format(slide))\n",
    "\t\t\n",
    "\t\tdf.loc[idx, 'process'] = 0\n",
    "\t\tslide_id, _ = os.path.splitext(slide)\n",
    "\n",
    "\t\tif auto_skip and os.path.isfile(os.path.join(patch_save_dir, slide_id + '.h5')):\n",
    "\t\t\tprint('{} already exist in destination location, skipped'.format(slide_id))\n",
    "\t\t\tdf.loc[idx, 'status'] = 'already_exist'\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\t# Inialize WSI\n",
    "\t\tfull_path = os.path.join(source, slide)\n",
    "\t\tWSI_object = WholeSlideImage(full_path)\n",
    "\n",
    "\t\tif use_default_params:\n",
    "\t\t\tcurrent_vis_params = vis_params.copy()\n",
    "\t\t\tcurrent_filter_params = filter_params.copy()\n",
    "\t\t\tcurrent_seg_params = seg_params.copy()\n",
    "\t\t\tcurrent_patch_params = patch_params.copy()\n",
    "\t\t\t\n",
    "\t\telse:\n",
    "\t\t\tcurrent_vis_params = {}\n",
    "\t\t\tcurrent_filter_params = {}\n",
    "\t\t\tcurrent_seg_params = {}\n",
    "\t\t\tcurrent_patch_params = {}\n",
    "\t\t\tfor key in vis_params.keys():\n",
    "\t\t\t\tcurrent_vis_params.update({key: df.loc[idx, key]})\n",
    "\n",
    "\t\t\tfor key in filter_params.keys():\n",
    "\t\t\t\tcurrent_filter_params.update({key: df.loc[idx, key]})\n",
    "\n",
    "\t\t\tfor key in seg_params.keys():\n",
    "\t\t\t\tcurrent_seg_params.update({key: df.loc[idx, key]})\n",
    "\n",
    "\t\t\tfor key in patch_params.keys():\n",
    "\t\t\t\tcurrent_patch_params.update({key: df.loc[idx, key]})\n",
    "\n",
    "\t\tif current_vis_params['vis_level'] < 0:\n",
    "\t\t\tif len(WSI_object.level_dim) == 1:\n",
    "\t\t\t\tcurrent_vis_params['vis_level'] = 0\n",
    "\t\t\t\n",
    "\t\t\telse:\t\n",
    "\t\t\t\twsi = WSI_object.getOpenSlide()\n",
    "\t\t\t\tbest_level = wsi.get_best_level_for_downsample(64)\n",
    "\t\t\t\tcurrent_vis_params['vis_level'] = best_level\n",
    "\n",
    "\t\tif current_seg_params['seg_level'] < 0:\n",
    "\t\t\tif len(WSI_object.level_dim) == 1:\n",
    "\t\t\t\tcurrent_seg_params['seg_level'] = 0\n",
    "\t\t\t\n",
    "\t\t\telse:\n",
    "\t\t\t\twsi = WSI_object.getOpenSlide()\n",
    "\t\t\t\tbest_level = wsi.get_best_level_for_downsample(64)\n",
    "\t\t\t\tcurrent_seg_params['seg_level'] = best_level\n",
    "\n",
    "\t\tkeep_ids = str(current_seg_params['keep_ids'])\n",
    "\t\tif keep_ids != 'none' and len(keep_ids) > 0:\n",
    "\t\t\tstr_ids = current_seg_params['keep_ids']\n",
    "\t\t\tcurrent_seg_params['keep_ids'] = np.array(str_ids.split(',')).astype(int)\n",
    "\t\telse:\n",
    "\t\t\tcurrent_seg_params['keep_ids'] = []\n",
    "\n",
    "\t\texclude_ids = str(current_seg_params['exclude_ids'])\n",
    "\t\tif exclude_ids != 'none' and len(exclude_ids) > 0:\n",
    "\t\t\tstr_ids = current_seg_params['exclude_ids']\n",
    "\t\t\tcurrent_seg_params['exclude_ids'] = np.array(str_ids.split(',')).astype(int)\n",
    "\t\telse:\n",
    "\t\t\tcurrent_seg_params['exclude_ids'] = []\n",
    "\n",
    "\t\tw, h = WSI_object.level_dim[current_seg_params['seg_level']] \n",
    "\t\tif w * h > 1e8:\n",
    "\t\t\tprint('level_dim {} x {} is likely too large for successful segmentation, aborting'.format(w, h))\n",
    "\t\t\tdf.loc[idx, 'status'] = 'failed_seg'\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tif not process_list:\n",
    "\t\t\tdf.loc[idx, 'vis_level'] = current_vis_params['vis_level']\n",
    "\t\t\tdf.loc[idx, 'seg_level'] = current_seg_params['seg_level']\n",
    "\n",
    "\t\tseg_time_elapsed = -1\n",
    "\t\tif seg:\n",
    "\t\t\tWSI_object, seg_time_elapsed = segment(WSI_object, current_seg_params, current_filter_params) \n",
    "\n",
    "\t\tif save_mask:\n",
    "\t\t\tmask = WSI_object.visWSI(**current_vis_params)\n",
    "\t\t\tmask_path = os.path.join(mask_save_dir, slide_id+'.png')\n",
    "\t\t\tmask.save(mask_path)\n",
    "\n",
    "\t\tpatch_time_elapsed = -1 # Default time\n",
    "\t\tif patch:\n",
    "\t\t\tcurrent_patch_params.update({'patch_level': patch_level, 'patch_size': patch_size, 'step_size': step_size, \n",
    "\t\t\t\t\t\t\t\t\t\t 'save_path': patch_save_dir, 'custom_downsample': custom_downsample})\n",
    "\t\t\tfile_path, patch_time_elapsed = patching(WSI_object = WSI_object, **current_patch_params)\n",
    "\t\t\n",
    "\t\tstitch_time_elapsed = -1\n",
    "\t\tif stitch:\n",
    "\t\t\tfile_path = os.path.join(patch_save_dir, slide_id+'.h5')\n",
    "\t\t\theatmap, stitch_time_elapsed = stitching(file_path, downscale=64)\n",
    "\t\t\tstitch_path = os.path.join(stitch_save_dir, slide_id+'.png')\n",
    "\t\t\theatmap.save(stitch_path)\n",
    "\n",
    "\t\tprint(\"segmentation took {} seconds\".format(seg_time_elapsed))\n",
    "\t\tprint(\"patching took {} seconds\".format(patch_time_elapsed))\n",
    "\t\tprint(\"stitching took {} seconds\".format(stitch_time_elapsed))\n",
    "\t\tdf.loc[idx, 'status'] = 'processed'\n",
    "\n",
    "\t\tseg_times += seg_time_elapsed\n",
    "\t\tpatch_times += patch_time_elapsed\n",
    "\t\tstitch_times += stitch_time_elapsed\n",
    "\n",
    "\tseg_times /= total\n",
    "\tpatch_times /= total\n",
    "\tstitch_times /= total\n",
    "\n",
    "\tdf.to_csv(os.path.join(save_dir, 'process_list_autogen.csv'), index=False)\n",
    "\tprint(\"average segmentation time in s per slide: {}\".format(seg_times))\n",
    "\tprint(\"average patching time in s per slide: {}\".format(patch_times))\n",
    "\tprint(\"average stiching time in s per slide: {}\".format(stitch_times))\n",
    "\t\t\n",
    "\treturn seg_times, patch_times\n",
    "\n",
    "parser = argparse.ArgumentParser(description='seg and patch')\n",
    "parser.add_argument('--source', type = str,\n",
    "\t\t\t\t\thelp='path to folder containing raw wsi image files')\n",
    "parser.add_argument('--step_size', type = int, default=256,\n",
    "\t\t\t\t\thelp='step_size')\n",
    "parser.add_argument('--patch_size', type = int, default=256,\n",
    "\t\t\t\t\thelp='patch_size')\n",
    "parser.add_argument('--patch', default=False, action='store_true')\n",
    "parser.add_argument('--seg', default=False, action='store_true')\n",
    "parser.add_argument('--stitch', default=False, action='store_true')\n",
    "parser.add_argument('--no_auto_skip', default=True, action='store_false')\n",
    "parser.add_argument('--save_dir', type = str,\n",
    "\t\t\t\t\thelp='directory to save processed data')\n",
    "parser.add_argument('--preset', default=None, type=str,\n",
    "\t\t\t\t\thelp='predefined profile of default segmentation and filter parameters (.csv)')\n",
    "parser.add_argument('--patch_level', type=int, default=0, \n",
    "\t\t\t\t\thelp='downsample level at which to patch')\n",
    "parser.add_argument('--custom_downsample', type= int, choices=[1,2], default=1, \n",
    "\t\t\t\t\thelp='custom downscale when native downsample is not available (only tested w/ 2x downscale)')\n",
    "parser.add_argument('--process_list',  type = str, default=None,\n",
    "\t\t\t\t\thelp='name of list of images to process with parameters (.csv)')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\targs = parser.parse_args()\n",
    "\n",
    "\tpatch_save_dir = os.path.join(args.save_dir, 'patches')\n",
    "\tmask_save_dir = os.path.join(args.save_dir, 'masks')\n",
    "\tstitch_save_dir = os.path.join(args.save_dir, 'stitches')\n",
    "\n",
    "\tif args.process_list:\n",
    "\t\tprocess_list = os.path.join(args.save_dir, args.process_list)\n",
    "\n",
    "\telse:\n",
    "\t\tprocess_list = None\n",
    "\n",
    "\tprint('source: ', args.source)\n",
    "\tprint('patch_save_dir: ', patch_save_dir)\n",
    "\tprint('mask_save_dir: ', mask_save_dir)\n",
    "\tprint('stitch_save_dir: ', stitch_save_dir)\n",
    "\t\n",
    "\tdirectories = {'source': args.source, \n",
    "\t\t\t\t   'save_dir': args.save_dir,\n",
    "\t\t\t\t   'patch_save_dir': patch_save_dir, \n",
    "\t\t\t\t   'mask_save_dir' : mask_save_dir, \n",
    "\t\t\t\t   'stitch_save_dir': stitch_save_dir} \n",
    "\n",
    "\tfor key, val in directories.items():\n",
    "\t\tprint(\"{} : {}\".format(key, val))\n",
    "\t\tif key not in ['source']:\n",
    "\t\t\tos.makedirs(val, exist_ok=True)\n",
    "\n",
    "\n",
    "\tseg_params = {'seg_level': -1, 'sthresh': 8, 'mthresh': 7, 'close': 4, 'use_otsu': False,\n",
    "\t\t\t\t  'keep_ids': 'none', 'exclude_ids': 'none'}\n",
    "\tfilter_params = {'a_t':100, 'a_h': 16, 'max_n_holes':8 }\n",
    "\tvis_params = {'vis_level': -1, 'line_thickness': 250}\n",
    "\tpatch_params = {'white_thresh': 5, 'black_thresh': 40, 'use_padding': True, 'contour_fn': 'four_pt'}\n",
    "\n",
    "\tif args.preset:\n",
    "\t\tpreset_df = pd.read_csv(os.path.join('presets', args.preset))\n",
    "\t\tfor key in seg_params.keys():\n",
    "\t\t\tseg_params[key] = preset_df.loc[0, key]\n",
    "\n",
    "\t\tfor key in filter_params.keys():\n",
    "\t\t\tfilter_params[key] = preset_df.loc[0, key]\n",
    "\n",
    "\t\tfor key in vis_params.keys():\n",
    "\t\t\tvis_params[key] = preset_df.loc[0, key]\n",
    "\n",
    "\t\tfor key in patch_params.keys():\n",
    "\t\t\tpatch_params[key] = preset_df.loc[0, key]\n",
    "\t\n",
    "\tparameters = {'seg_params': seg_params,\n",
    "\t\t\t\t  'filter_params': filter_params,\n",
    "\t \t\t\t  'patch_params': patch_params,\n",
    "\t\t\t\t  'vis_params': vis_params}\n",
    "\n",
    "\tprint(parameters)\n",
    "\n",
    "\tseg_times, patch_times = seg_and_patch(**directories, **parameters,\n",
    "\t\t\t\t\t\t\t\t\t\t\tpatch_size = args.patch_size, step_size=args.step_size, \n",
    "\t\t\t\t\t\t\t\t\t\t\tseg = args.seg,  use_default_params=False, save_mask = True, \n",
    "\t\t\t\t\t\t\t\t\t\t\tstitch= args.stitch, custom_downsample = args.custom_downsample, \n",
    "\t\t\t\t\t\t\t\t\t\t\tpatch_level=args.patch_level, patch = args.patch,\n",
    "\t\t\t\t\t\t\t\t\t\t\tprocess_list = process_list, auto_skip=args.no_auto_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765fef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# internal imports\n",
    "from wsi_core.WholeSlideImage import WholeSlideImage \n",
    "from wsi_core.wsi_utils import StitchPatches\n",
    "from wsi_core.batch_process_utils import initialize_df\n",
    "# other imports\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import pdb\n",
    "import pandas as pd\n",
    "\n",
    "def stitching(file_path, downscale = 64):\n",
    "    start = time.time()\n",
    "\theatmap = StitchPatches(file_path, downscale=downscale, bg_color=(0,0,0), alpha=-1, draw_grid=False)\n",
    "\ttotal_time = time.time() - start\n",
    "\t\n",
    "\treturn heatmap, total_time\n",
    "\n",
    "def segment(WSI_object, seg_params, filter_params):\n",
    "\t### Start Seg Timer\n",
    "\tstart_time = time.time()\n",
    "\n",
    "\t# Segment\n",
    "\tWSI_object.segmentTissue(**seg_params, filter_params=filter_params)\n",
    "\n",
    "\t### Stop Seg Timers\n",
    "\tseg_time_elapsed = time.time() - start_time   \n",
    "\treturn WSI_object, seg_time_elapsed\n",
    "\n",
    "def patching(WSI_object, **kwargs):\n",
    "\t### Start Patch Timer\n",
    "\tstart_time = time.time()\n",
    "\n",
    "\t# Patch\n",
    "\tfile_path = WSI_object.createPatches_bag_hdf5(**kwargs, save_coord=True)\n",
    "\n",
    "\t### Stop Patch Timer\n",
    "\tpatch_time_elapsed = time.time() - start_time\n",
    "\treturn file_path, patch_time_elapsed\n",
    "\n",
    "def seg_and_patch(source, save_dir, patch_save_dir, mask_save_dir, stitch_save_dir, \n",
    "\t\t\t\t  patch_size = 256, step_size = 256, custom_downsample=1, \n",
    "\t\t\t\t  seg_params = {'seg_level': -1, 'sthresh': 8, 'mthresh': 7, 'close': 4, 'use_otsu': False,\n",
    "\t\t\t\t  'keep_ids': 'none', 'exclude_ids': 'none'},\n",
    "\t\t\t\t  filter_params = {'a_t':100, 'a_h': 16, 'max_n_holes':8 }, \n",
    "\t\t\t\t  vis_params = {'vis_level': -1, 'line_thickness': 250},\n",
    "\t\t\t\t  patch_params = {'white_thresh': 5, 'black_thresh': 40, 'use_padding': True, 'contour_fn': 'four_pt'},\n",
    "\t\t\t\t  patch_level = 0,\n",
    "\t\t\t\t  use_default_params = False, \n",
    "\t\t\t\t  seg = False, save_mask = True, \n",
    "\t\t\t\t  stitch= False, \n",
    "\t\t\t\t  patch = False, auto_skip=True, process_list = None):\n",
    "\t\n",
    "\n",
    "\n",
    "\tslides = sorted(os.listdir(source))\n",
    "\tslides = [slide for slide in slides if os.path.isfile(os.path.join(source, slide))]\n",
    "\n",
    "\tif process_list is None:\n",
    "\t\tdf = initialize_df(slides, seg_params, filter_params, vis_params, patch_params, save_patches=True)\n",
    "\t\n",
    "\telse:\n",
    "\t\tdf = pd.read_csv(process_list)\n",
    "\t\tdf = initialize_df(df, seg_params, filter_params, vis_params, patch_params, save_patches=True)\n",
    "\n",
    "\n",
    "\tmask = df['process'] == 1\n",
    "\tprocess_stack = df[mask]\n",
    "\n",
    "\ttotal = len(process_stack)\n",
    "\tseg_times = 0.\n",
    "\tpatch_times = 0.\n",
    "\tstitch_times = 0.\n",
    "\n",
    "\tfor i in range(total):\n",
    "\t\tdf.to_csv(os.path.join(save_dir, 'process_list_autogen.csv'), index=False)\n",
    "\t\tidx = process_stack.index[i]\n",
    "\t\tslide = process_stack.loc[idx, 'slide_id']\n",
    "\t\tprint(\"\\n\\nprogress: {:.2f}, {}/{}\".format(i/total, i, total))\n",
    "\t\tprint('processing {}'.format(slide))\n",
    "\t\t\n",
    "\t\tdf.loc[idx, 'process'] = 0\n",
    "\t\tslide_id, _ = os.path.splitext(slide)\n",
    "\n",
    "\t\tif auto_skip and os.path.isfile(os.path.join(patch_save_dir, slide_id + '.h5')):\n",
    "\t\t\tprint('{} already exist in destination location, skipped'.format(slide_id))\n",
    "\t\t\tdf.loc[idx, 'status'] = 'already_exist'\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\t# Inialize WSI\n",
    "\t\tfull_path = os.path.join(source, slide)\n",
    "\t\tWSI_object = WholeSlideImage(full_path)\n",
    "\n",
    "\t\tif use_default_params:\n",
    "\t\t\tcurrent_vis_params = vis_params.copy()\n",
    "\t\t\tcurrent_filter_params = filter_params.copy()\n",
    "\t\t\tcurrent_seg_params = seg_params.copy()\n",
    "\t\t\tcurrent_patch_params = patch_params.copy()\n",
    "\t\t\t\n",
    "\t\telse:\n",
    "\t\t\tcurrent_vis_params = {}\n",
    "\t\t\tcurrent_filter_params = {}\n",
    "\t\t\tcurrent_seg_params = {}\n",
    "\t\t\tcurrent_patch_params = {}\n",
    "\t\t\tfor key in vis_params.keys():\n",
    "\t\t\t\tcurrent_vis_params.update({key: df.loc[idx, key]})\n",
    "\n",
    "\t\t\tfor key in filter_params.keys():\n",
    "\t\t\t\tcurrent_filter_params.update({key: df.loc[idx, key]})\n",
    "\n",
    "\t\t\tfor key in seg_params.keys():\n",
    "\t\t\t\tcurrent_seg_params.update({key: df.loc[idx, key]})\n",
    "\n",
    "\t\t\tfor key in patch_params.keys():\n",
    "\t\t\t\tcurrent_patch_params.update({key: df.loc[idx, key]})\n",
    "\n",
    "\t\tif current_vis_params['vis_level'] < 0:\n",
    "\t\t\tif len(WSI_object.level_dim) == 1:\n",
    "\t\t\t\tcurrent_vis_params['vis_level'] = 0\n",
    "\t\t\t\n",
    "\t\t\telse:\t\n",
    "\t\t\t\twsi = WSI_object.getOpenSlide()\n",
    "\t\t\t\tbest_level = wsi.get_best_level_for_downsample(64)\n",
    "\t\t\t\tcurrent_vis_params['vis_level'] = best_level\n",
    "\n",
    "\t\tif current_seg_params['seg_level'] < 0:\n",
    "\t\t\tif len(WSI_object.level_dim) == 1:\n",
    "\t\t\t\tcurrent_seg_params['seg_level'] = 0\n",
    "\t\t\t\n",
    "\t\t\telse:\n",
    "\t\t\t\twsi = WSI_object.getOpenSlide()\n",
    "\t\t\t\tbest_level = wsi.get_best_level_for_downsample(64)\n",
    "\t\t\t\tcurrent_seg_params['seg_level'] = best_level\n",
    "\n",
    "\t\tkeep_ids = str(current_seg_params['keep_ids'])\n",
    "\t\tif keep_ids != 'none' and len(keep_ids) > 0:\n",
    "\t\t\tstr_ids = current_seg_params['keep_ids']\n",
    "\t\t\tcurrent_seg_params['keep_ids'] = np.array(str_ids.split(',')).astype(int)\n",
    "\t\telse:\n",
    "\t\t\tcurrent_seg_params['keep_ids'] = []\n",
    "\n",
    "\t\texclude_ids = str(current_seg_params['exclude_ids'])\n",
    "\t\tif exclude_ids != 'none' and len(exclude_ids) > 0:\n",
    "\t\t\tstr_ids = current_seg_params['exclude_ids']\n",
    "\t\t\tcurrent_seg_params['exclude_ids'] = np.array(str_ids.split(',')).astype(int)\n",
    "\t\telse:\n",
    "\t\t\tcurrent_seg_params['exclude_ids'] = []\n",
    "\n",
    "\t\tw, h = WSI_object.level_dim[current_seg_params['seg_level']] \n",
    "\t\tif w * h > 1e8:\n",
    "\t\t\tprint('level_dim {} x {} is likely too large for successful segmentation, aborting'.format(w, h))\n",
    "\t\t\tdf.loc[idx, 'status'] = 'failed_seg'\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tif not process_list:\n",
    "\t\t\tdf.loc[idx, 'vis_level'] = current_vis_params['vis_level']\n",
    "\t\t\tdf.loc[idx, 'seg_level'] = current_seg_params['seg_level']\n",
    "\n",
    "\t\tseg_time_elapsed = -1\n",
    "\t\tif seg:\n",
    "\t\t\tWSI_object, seg_time_elapsed = segment(WSI_object, current_seg_params, current_filter_params) \n",
    "\n",
    "\t\tif save_mask:\n",
    "\t\t\tmask = WSI_object.visWSI(**current_vis_params)\n",
    "\t\t\tmask_path = os.path.join(mask_save_dir, slide_id+'.png')\n",
    "\t\t\tmask.save(mask_path)\n",
    "\n",
    "\t\tpatch_time_elapsed = -1 # Default time\n",
    "\t\tif patch:\n",
    "\t\t\tcurrent_patch_params.update({'patch_level': patch_level, 'patch_size': patch_size, 'step_size': step_size, \n",
    "\t\t\t\t\t\t\t\t\t\t 'save_path': patch_save_dir, 'custom_downsample': custom_downsample})\n",
    "\t\t\tfile_path, patch_time_elapsed = patching(WSI_object = WSI_object, **current_patch_params)\n",
    "\t\t\n",
    "\t\tstitch_time_elapsed = -1\n",
    "\t\tif stitch:\n",
    "\t\t\tfile_path = os.path.join(patch_save_dir, slide_id+'.h5')\n",
    "\t\t\theatmap, stitch_time_elapsed = stitching(file_path, downscale=64)\n",
    "\t\t\tstitch_path = os.path.join(stitch_save_dir, slide_id+'.png')\n",
    "\t\t\theatmap.save(stitch_path)\n",
    "\n",
    "\t\tprint(\"segmentation took {} seconds\".format(seg_time_elapsed))\n",
    "\t\tprint(\"patching took {} seconds\".format(patch_time_elapsed))\n",
    "\t\tprint(\"stitching took {} seconds\".format(stitch_time_elapsed))\n",
    "\t\tdf.loc[idx, 'status'] = 'processed'\n",
    "\n",
    "\t\tseg_times += seg_time_elapsed\n",
    "\t\tpatch_times += patch_time_elapsed\n",
    "\t\tstitch_times += stitch_time_elapsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b83f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# internal imports\n",
    "from wsi_core.WholeSlideImage import WholeSlideImage \n",
    "from wsi_core.wsi_utils import StitchPatches\n",
    "from wsi_core.batch_process_utils import initialize_df\n",
    "# other imports\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import pdb\n",
    "import pandas as pd\n",
    "\n",
    "def stitching(file_path, downscale = 64):\n",
    "    start = time.time()\n",
    "\theatmap = StitchPatches(file_path, downscale=downscale, bg_color=(0,0,0), alpha=-1, draw_grid=False)\n",
    "\ttotal_time = time.time() - start\n",
    "\t\n",
    "\treturn heatmap, total_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242f7b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from WholeSlideImage import WSI\n",
    "from wsi_utils import StitchPatches\n",
    "from batch_process_utils import initizalize_df\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import pdb\n",
    "import pandas as pd\n",
    "\n",
    "def stitching(file_path, downscale = 64):\n",
    "    start = time.time()\n",
    "    heatmap = StitchPatches(file_path, downscale = downscale, bg_color = (0,0,0), alpha = -1, draw_grid = False)\n",
    "    total_itime = time.time() - start\n",
    "    \n",
    "    return heatmap, total_time\n",
    "\n",
    "#이 함수를 통해 StitchPatches라는 함수를 호출한 후에 이를 실행한 시간을 계산하도록 한다. StitchPatches는 원래 wsi_utils로부터 나오는 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f626f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(WSI_object, seg_params, filter_params):\n",
    "\t### Start Seg Timer\n",
    "\tstart_time = time.time()\n",
    "\n",
    "\t# Segment\n",
    "\tWSI_object.segmentTissue(**seg_params, filter_params=filter_params)\n",
    "\n",
    "\t### Stop Seg Timers\n",
    "\tseg_time_elapsed = time.time() - start_time   \n",
    "\treturn WSI_object, seg_time_elapsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e00961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment(WSI_object, seg_params, filter_params):\n",
    "    start+time = time.time()\n",
    "    WSI_object.segmentTissue(**seg_params, filter_params = filter_params)\n",
    "    \n",
    "    seg_time_elapsed = time.time() - start_time\n",
    "    return WSI_object, seg_time_elapsed\n",
    "\n",
    "\n",
    "#이 코드를 통해 segment를 한다. 어떻게 하는거지? \n",
    "#object를 통해 객체 처리를 하는 것으로 보이고 그 후에는 seg_params의 주소. 즉 seg_params는 하나의 배열 또는 matrix가 될 것이다.\n",
    "#그 후에 걸린 시간을 보여준다. key는 하나의 함수를 어떻게 실행하는가 - 거기에 있는 것으로 보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e266dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def patching(WSI_object, **kwargs):\n",
    "\t### Start Patch Timer\n",
    "\tstart_time = time.time()\n",
    "\n",
    "\t# Patch\n",
    "\tfile_path = WSI_object.createPatches_bag_hdf5(**kwargs, save_coord=True)\n",
    "\n",
    "\t### Stop Patch Timer\n",
    "\tpatch_time_elapsed = time.time() - start_time\n",
    "\treturn file_path, patch_time_elapsed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "033c2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patching(WSI_object, **kwargs): # 도대체 WSI_object는 무슨 객체인가? dataset을 어떻게 설계해낼 수 있을까? 결국에 한 번 해보자는 거지.\n",
    "    #회사 일도 이런 식으로 이루어지는 것이 아닐까? 세상의 온갖 일들이 어떻게 이루어지는지.\n",
    "    start_time = time.time()\n",
    "    \n",
    "    file_path = WSI_object.createPatches_bag_hdf5(**kwargs, save_coord = True)\n",
    "    \n",
    "    patch_time_elapsed = time.time() - start_time\n",
    "    return file_path, patch_time_elapsed\n",
    "#각 단계를 통해서 kwarg라는 배열에 함수의 결과값을 집어넣는다. 어떻게 집어넣는가? 잘 모르겠다. 그러나 할 수 있을 것으로 보인다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0856e52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def seg_and_patch(source, save_dir, patch_save_dir, mask_save_dir, stitch_save_dir, \n",
    "\t\t\t\t  patch_size = 256, step_size = 256, custom_downsample=1, \n",
    "\t\t\t\t  seg_params = {'seg_level': -1, 'sthresh': 8, 'mthresh': 7, 'close': 4, 'use_otsu': False,\n",
    "\t\t\t\t  'keep_ids': 'none', 'exclude_ids': 'none'},\n",
    "\t\t\t\t  filter_params = {'a_t':100, 'a_h': 16, 'max_n_holes':8 }, \n",
    "\t\t\t\t  vis_params = {'vis_level': -1, 'line_thickness': 250},\n",
    "\t\t\t\t  patch_params = {'white_thresh': 5, 'black_thresh': 40, 'use_padding': True, 'contour_fn': 'four_pt'},\n",
    "\t\t\t\t  patch_level = 0,\n",
    "\t\t\t\t  use_default_params = False, \n",
    "\t\t\t\t  seg = False, save_mask = True, \n",
    "\t\t\t\t  stitch= False, \n",
    "\t\t\t\t  patch = False, auto_skip=True, process_list = None):\n",
    "\t\n",
    "\n",
    "\n",
    "\tslides = sorted(os.listdir(source))\n",
    "\tslides = [slide for slide in slides if os.path.isfile(os.path.join(source, slide))]\n",
    "\n",
    "\tif process_list is None:\n",
    "\t\tdf = initialize_df(slides, seg_params, filter_params, vis_params, patch_params, save_patches=True)\n",
    "\t\n",
    "\telse:\n",
    "\t\tdf = pd.read_csv(process_list)\n",
    "\t\tdf = initialize_df(df, seg_params, filter_params, vis_params, patch_params, save_patches=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a7b73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seg_and_patch(source, savedir, patch_save_dir, mask_save_dir, stitch_save_dir,\n",
    "                 patch_size = 256, step_size = 256, custom_downsample = 1,\n",
    "                 seg_params = {'seg_level': = -1, 'sthresh': 8, 'mthresh':7, 'close':4,'use_otsu':False,\n",
    "                    'keep_ids': 'none', 'exclued_ids':none},\n",
    "                 filter_params = {'a_t':100, 'a_h': 16, 'max_n_holes':8},\n",
    "                 vis_params = {'vis_level':-1, 'line_thickness':250},\n",
    "                 patch_params={'white_thresh':5, 'black_thresh':40, 'use_padding':True, 'contour_fn':four_pt},\n",
    "                 patch_level=0,\n",
    "                 use_default_params=False,\n",
    "                 seg = False, save_mask=True,\n",
    "                 stitch= False,\n",
    "                 patch=False, auto_skip=True, process_list = None):\n",
    "    slides = sorted(os.listdir(source))\n",
    "    slides = [slide for slide in slides if os.path.isfile(os.path.join(source, slide))]\n",
    "    \n",
    "    if process_list is None:\n",
    "        df = initizalize_df(slies, seg_params, filter_params, vis_params, patch_params, save_patches=True)\n",
    "        \n",
    "    else:\n",
    "        df = pd.read_csv(process_list)\n",
    "        df = initialize_df(df, seg_params, filter_params, vis_params, patch_params, save_patches=True)\n",
    "        \n",
    "#왜 df의 정의를 다르게 하는가? process_list가 무엇이기에? 그리고 \n",
    "#어디에서 이런 함수를 정의해서 가져오는 것이지? 궁금하다 - 계속해서 알아가고 전체 체계를 숙지하도록 노력한다.\n",
    "\n",
    "#일단, 하나의 함수를 정의하고자 하고, 여러 가지 모든 변수들을 가져와서 정의한 후에 이들을 가지고 slidde, df를 만들어낸다. 이것이 첫 번쨰이다.\n",
    "#각각의 슬라이드에 대한 정보를 중심으로 pandas df를 만들어내는 것으로 보인다. 그러나 process_list의 존재가 왜 필요한지가 의문이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96daa39c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a59b412",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\tmask = df['process'] == 1\n",
    "\tprocess_stack = df[mask]\n",
    "\n",
    "\ttotal = len(process_stack)\n",
    "\tseg_times = 0.\n",
    "\tpatch_times = 0.\n",
    "\tstitch_times = 0.\n",
    "\n",
    "\tfor i in range(total):\n",
    "\t\tdf.to_csv(os.path.join(save_dir, 'process_list_autogen.csv'), index=False)\n",
    "\t\tidx = process_stack.index[i]\n",
    "\t\tslide = process_stack.loc[idx, 'slide_id']\n",
    "\t\tprint(\"\\n\\nprogress: {:.2f}, {}/{}\".format(i/total, i, total))\n",
    "\t\tprint('processing {}'.format(slide))\n",
    "\t\t\n",
    "\t\tdf.loc[idx, 'process'] = 0\n",
    "\t\tslide_id, _ = os.path.splitext(slide)\n",
    "\n",
    "\t\tif auto_skip and os.path.isfile(os.path.join(patch_save_dir, slide_id + '.h5')):\n",
    "\t\t\tprint('{} already exist in destination location, skipped'.format(slide_id))\n",
    "\t\t\tdf.loc[idx, 'status'] = 'already_exist'\n",
    "\t\t\tcontinue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b040fb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mask \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocess\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      2\u001b[0m process_stack \u001b[38;5;241m=\u001b[39m df[mask]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "    mask = df['process'] == 1\n",
    "    process_stack = df[mask]\n",
    "    #? 도대체 무슨 일이 벌어지는 거지\n",
    "    #1. process_list, 그리고 만들어진 initialize_df가 어디 있는지, 어떤 역할 하는지 알아보자.\n",
    "    #전체 흐름 속에서 무엇이 돌아가는지 알아가고자 하는 흐름을 보고자 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6605b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdb\n",
    "\t\n",
    "'''\n",
    "initiate a pandas df describing a list of slides to process\n",
    "args:\n",
    "\tslides (df or array-like): \n",
    "\t\tarray-like structure containing list of slide ids, if df, these ids assumed to be\n",
    "\t\tstored under the 'slide_id' column\n",
    "\tseg_params (dict): segmentation paramters \n",
    "\tfilter_params (dict): filter parameters\n",
    "\tvis_params (dict): visualization paramters\n",
    "\tpatch_params (dict): patching paramters\n",
    "\tuse_heatmap_args (bool): whether to include heatmap arguments such as ROI coordinates\n",
    "'''\n",
    "def initialize_df(slides, seg_params, filter_params, vis_params, patch_params, \n",
    "\tuse_heatmap_args=False, save_patches=False):\n",
    "\n",
    "\ttotal = len(slides)\n",
    "\tif isinstance(slides, pd.DataFrame):\n",
    "\t\tslide_ids = slides.slide_id.values\n",
    "\telse:\n",
    "\t\tslide_ids = slides\n",
    "\tdefault_df_dict = {'slide_id': slide_ids, 'process': np.full((total), 1, dtype=np.uint8)}\n",
    "\n",
    "\t# initiate empty labels in case not provided\n",
    "\tif use_heatmap_args:\n",
    "\t\tdefault_df_dict.update({'label': np.full((total), -1)})\n",
    "\t\n",
    "\tdefault_df_dict.update({\n",
    "\t\t'status': np.full((total), 'tbp'),\n",
    "\t\t# seg params\n",
    "\t\t'seg_level': np.full((total), int(seg_params['seg_level']), dtype=np.int8),\n",
    "\t\t'sthresh': np.full((total), int(seg_params['sthresh']), dtype=np.uint8),\n",
    "\t\t'mthresh': np.full((total), int(seg_params['mthresh']), dtype=np.uint8),\n",
    "\t\t'close': np.full((total), int(seg_params['close']), dtype=np.uint32),\n",
    "\t\t'use_otsu': np.full((total), bool(seg_params['use_otsu']), dtype=bool),\n",
    "\t\t'keep_ids': np.full((total), seg_params['keep_ids']),\n",
    "\t\t'exclude_ids': np.full((total), seg_params['exclude_ids']),\n",
    "\t\t\n",
    "\t\t# filter params\n",
    "\t\t'a_t': np.full((total), int(filter_params['a_t']), dtype=np.float32),\n",
    "\t\t'a_h': np.full((total), int(filter_params['a_h']), dtype=np.float32),\n",
    "\t\t'max_n_holes': np.full((total), int(filter_params['max_n_holes']), dtype=np.uint32),\n",
    "\n",
    "\t\t# vis params\n",
    "\t\t'vis_level': np.full((total), int(vis_params['vis_level']), dtype=np.int8),\n",
    "\t\t'line_thickness': np.full((total), int(vis_params['line_thickness']), dtype=np.uint32),\n",
    "\n",
    "\t\t# patching params\n",
    "\t\t'use_padding': np.full((total), bool(patch_params['use_padding']), dtype=bool),\n",
    "\t\t'contour_fn': np.full((total), patch_params['contour_fn'])\n",
    "\t\t})\n",
    "\n",
    "\tif save_patches:\n",
    "\t\tdefault_df_dict.update({\n",
    "\t\t\t'white_thresh': np.full((total), int(patch_params['white_thresh']), dtype=np.uint8),\n",
    "\t\t\t'black_thresh': np.full((total), int(patch_params['black_thresh']), dtype=np.uint8)})\n",
    "\n",
    "\tif use_heatmap_args:\n",
    "\t\t# initiate empty x,y coordinates in case not provided\n",
    "\t\tdefault_df_dict.update({'x1': np.empty((total)).fill(np.NaN), \n",
    "\t\t\t'x2': np.empty((total)).fill(np.NaN), \n",
    "\t\t\t'y1': np.empty((total)).fill(np.NaN), \n",
    "\t\t\t'y2': np.empty((total)).fill(np.NaN)})\n",
    "\n",
    "\n",
    "\tif isinstance(slides, pd.DataFrame):\n",
    "\t\ttemp_copy = pd.DataFrame(default_df_dict) # temporary dataframe w/ default params\n",
    "\t\t# find key in provided df\n",
    "\t\t# if exist, fill empty fields w/ default values, else, insert the default values as a new column\n",
    "\t\tfor key in default_df_dict.keys(): \n",
    "\t\t\tif key in slides.columns:\n",
    "\t\t\t\tmask = slides[key].isna()\n",
    "\t\t\t\tslides.loc[mask, key] = temp_copy.loc[mask, key]\n",
    "\t\t\telse:\n",
    "\t\t\t\tslides.insert(len(slides.columns), key, default_df_dict[key])\n",
    "\telse:\n",
    "\t\tslides = pd.DataFrame(default_df_dict)\n",
    "\t\n",
    "\treturn slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d25739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdb\n",
    "\t\n",
    "'''\n",
    "initiate a pandas df describing a list of slides to process\n",
    "args:\n",
    "\tslides (df or array-like): \n",
    "\t\tarray-like structure containing list of slide ids, if df, these ids assumed to be\n",
    "\t\tstored under the 'slide_id' column\n",
    "\tseg_params (dict): segmentation paramters \n",
    "\tfilter_params (dict): filter parameters\n",
    "\tvis_params (dict): visualization paramters\n",
    "\tpatch_params (dict): patching paramters\n",
    "\tuse_heatmap_args (bool): whether to include heatmap arguments such as ROI coordinates\n",
    "'''\n",
    "def initialize_df(slides, seg_params, filter_params, vis_params, patch_params, \n",
    "\tuse_heatmap_args=False, save_patches=False):\n",
    "\n",
    "\ttotal = len(slides)  # 슬라이드의 총 개수를 구합니다.\n",
    "\tif isinstance(slides, pd.DataFrame):  # 슬라이드가 DataFrame인지 확인합니다.\n",
    "\t\tslide_ids = slides.slide_id.values  # 슬라이드 ID를 가져옵니다.\n",
    "\telse:\n",
    "\t\tslide_ids = slides  # 슬라이드가 DataFrame이 아닌 경우 그대로 사용합니다.\n",
    "\tdefault_df_dict = {'slide_id': slide_ids, 'process': np.full((total), 1, dtype=np.uint8)}  # 데이터프레임의 기본 구조를 만듭니다.\n",
    "\n",
    "\t# initiate empty labels in case not provided\n",
    "\tif use_heatmap_args:  # 히트맵 인수를 사용할지 여부를 확인합니다.\n",
    "\t\tdefault_df_dict.update({'label': np.full((total), -1)})  # 히트맵 인수가 사용되는 경우 'label' 열을 생성합니다.\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f97f584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "'''\n",
    "initiate a pandas df describing a list of slides to process args:\n",
    "slides(df or array-like):\n",
    "    array-like structure containing list of slide ids, if df, these ids assumed to be stored under the 'slide_i' column\n",
    "and other parameters available'''\n",
    "\n",
    "def initialize_df(slides, seg_params, filter_params, vis_params, patch_params,\n",
    "                 use_heatmap_args=False, save_patches = False):\n",
    "    total = len(slides) #슬라이드 총 개수 구하기\n",
    "    if isinstance(slides, pd.DataFrame): # 슬라이드 DataFrame인지 확인! 제대로 구현해보지.\n",
    "        slide_ids = slides.slide_id.values\n",
    "    else: #슬라이드가 그냥 slide list로 주어진다면.\n",
    "        slide_ids = slides\n",
    "    #이렇게 slide_id를 구해왔다.\n",
    "    defalut_dict = {'slide_id':slide_ids, 'process':np.full((total), 1, dtype = np.uint8)} #dataframe 기본 구조 만들기?? - what is it?\n",
    "    \n",
    "    # initiate empty labels in case not provides-d\n",
    "    if use_heatmap_args:\n",
    "        default_df_dict.update({'label':np.full((total)-1)})\n",
    "#결국에 경우가 나눠진다는거는\n",
    "#언젠가 그걸 통합하는 상황에서의 추상화 또는 일들이 이뤄지게 되는구나."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7237a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\tdefault_df_dict.update({\n",
    "\t\t'status': np.full((total), 'tbp'),  # 'status' 열을 생성하고 초기화합니다.\n",
    "\t\t# seg params\n",
    "\t\t'seg_level': np.full((total), int(seg_params['seg_level']), dtype=np.int8),  # 'seg_level' 열을 생성하고 초기화합니다.\n",
    "\t\t'sthresh': np.full((total), int(seg_params['sthresh']), dtype=np.uint8),  # 'sthresh' 열을 생성하고 초기화합니다.\n",
    "\t\t'mthresh': np.full((total), int(seg_params['mthresh']), dtype=np.uint8),  # 'mthresh' 열을 생성하고 초기화합니다.\n",
    "\t\t'close': np.full((total), int(seg_params['close']), dtype=np.uint32),  # 'close' 열을 생성하고 초기화합니다.\n",
    "\t\t'use_otsu': np.full((total), bool(seg_params['use_otsu']), dtype=bool),  # 'use_otsu' 열을 생성하고 초기화합니다.\n",
    "\t\t'keep_ids': np.full((total), seg_params['keep_ids']),  # 'keep_ids' 열을 생성하고 초기화합니다.\n",
    "\t\t'exclude_ids': np.full((total), seg_params['exclude_ids']),  # 'exclude_ids' 열을 생성하고 초기화합니다.\n",
    "\t\t\n",
    "\t\t# filter params\n",
    "\t\t'a_t': np.full((total), int(filter_params['a_t']), dtype=np.float32),  # 'a_t' 열을 생성하고 초기화합니다.\n",
    "\t\t'a_h': np.full((total), int(filter_params['a_h']), dtype=np.float32),  # 'a_h' 열을 생성하고 초기화합니다.\n",
    "\t\t'max_n_holes': np.full((total), int(filter_params['max_n_holes']), dtype=np.uint32),  # 'max_n_holes' 열을 생성하고 초기화합니다.\n",
    "\n",
    "\t\t# vis params\n",
    "\t\t'vis_level': np.full((total), int(vis_params['vis_level']), dtype=np.int8),  # 'vis_level' 열을 생성하고 초기화합니다.\n",
    "\t\t'line_thickness': np.full((total), int(vis_params['line_thickness']), dtype=np.uint32),  # 'line_thickness' 열을 생성하고 초기화합니다.\n",
    "\n",
    "\t\t# patching params\n",
    "\t\t'use_padding': np.full((total), bool(patch_params['use_padding']), dtype=bool),  # 'use_padding' 열을 생성하고 초기화합니다.\n",
    "\t\t'contour_fn': np.full((total), patch_params['contour_fn'])  # 'contour_fn' 열을 생성하고 초기화합니다.\n",
    "\t\t})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3711480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_df_dict.update({\n",
    "    'status':np.full((total), 'tbp'),\n",
    "# ...    \n",
    "})\n",
    "\n",
    "# 등등 여러 열들을 생성해준다. 각 열을 생성해서 이분들은 어디에 쓰려는 생각인 것이지? 보고 생각해보아야겠다.\n",
    "\n",
    "# 모든 사람들이 생각보다 '생각'으로 이루어져 있다는 사실이 새삼스럽게 느껴지기도 한다. 모두가 같은 사람이고 이해할만한 생각으로\n",
    "# 세상을 만들고 ㅂㄴ형하고 지배해 나간다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a13fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\tif save_patches:  # 패치를 저장할지 여부를 확인합니다.\n",
    "\t\tdefault_df_dict.update({\n",
    "\t\t\t'white_thresh': np.full((total), int(patch_params['white_thresh']), dtype=np.uint8),  # 'white_thresh' 열을 생성하고 초기화합니다.\n",
    "\t\t\t'black_thresh': np.full((total), int(patch_params['black_thresh']), dtype=np.uint8)})  # 'black_thresh' 열을 생성하고 초기화합니다.\n",
    "\n",
    "\tif use_heatmap_args:  # 히트맵 인수를 사용할지 여부를 확인합니다.\n",
    "\t\t# initiate empty x,y coordinates in case not provided\n",
    "\t\tdefault_df_dict.update({'x1': np.empty((total)).fill(np.NaN),  # 'x1' 열을 생성하고 초기화합니다.\n",
    "\t\t\t'x2': np.empty((total)).fill(np.NaN),  # 'x2' 열을 생성하고 초기화합니다.\n",
    "\t\t\t'y1': np.empty((total)).fill(np.NaN),  # 'y1' 열을 생성하고 초기화합니다.\n",
    "\t\t\t'y2': np.empty((total)).fill(np.NaN)})  # 'y2' 열을 생성하고 초기화합니다.\n",
    "\n",
    "\n",
    "\tif isinstance(slides, pd.DataFrame):  # 슬라이드가 DataFrame인지 확인합니다.\n",
    "\t\ttemp_copy = pd.DataFrame(default_df_dict)  # 데이터프레임의 복사본을 만듭니다.\n",
    "\t\t# find key in provided df\n",
    "\t\t# if exist, fill empty fields w/ default values, else, insert the default values as a new column\n",
    "\t\tfor key in default_df_dict.keys():  # 각 열을 확인하면서\n",
    "\t\t\tif key in slides.columns:  # 만약 주어진 데이터프레임에 열이 이미 존재한다면\n",
    "\t\t\t\tmask = slides[key].isna()  # 누락된 값이 있는지 확인하고\n",
    "\t\t\t\tslides.loc[mask, key] = temp_copy.loc[mask, key]  # 누락된 값에 기본 값을 채웁니다.\n",
    "\t\t\telse:  # 주어진 데이터프레임에 열이 존재하지 않는 경우\n",
    "\t\t\t\tslides.insert(len(slides.columns), key, default_df_dict[key])  # 새로운 열을 추가하고 기본 값을 채웁니다.\n",
    "\telse:  # 슬라이드가 DataFrame이 아닌 경우\n",
    "\t\tslides = pd.DataFrame(default_df_dict)  # 새로운 데이터프레임을 생성하고 초기화합니다.\n",
    "\t\n",
    "\treturn slides  # 초기화된 데이터프레임을 반환합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81353c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if save_patches:\n",
    "        default_df_dict.update({\n",
    "            'white_thresh':np.full((total), int(patch_params['white_thresh']),dtype=np.uint8),\n",
    "            'black_thresh':np.full((total),int(patch_params['black_thresh']),dtype=np.uint8)\n",
    "        })\n",
    "    if use_heatmap_args:\n",
    "        #initiate empty x, y coordinates in case not provided\n",
    "        default_df_dict.update({'x1':np.empty((total)).fill(np.NaN),\n",
    "                               'x2':np.empty((total)).fill(np.NaN),\n",
    "                               'y1':np.empty((total)).fill(np.NaN),\n",
    "                               'y2':np.empty((total)).fill(np.NaN)})\n",
    "    if isinstance(slides, pd.DataFrame):\n",
    "        temp_copy = pd.DataFrame(default_df_dict)\n",
    "        #find key in proveded df\n",
    "        for key in default_df_dict.keys():\n",
    "            if key in slides.columns:\n",
    "                mask = slides[key].isna()\n",
    "                slides.loc[mask, key] = temp_copy.loc[mask, key]\n",
    "            else:\n",
    "                slides.insert(len(slides.columns),key,default_df_dict[key])\n",
    "    else:\n",
    "        slides=pd.DataFrame(default_df_dict)\n",
    "    return slides\n",
    "\n",
    "#이렇게 하나의 DF를 만들어내고 정의해낸다. 슬라이드로부터 정보를 얻어낸다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
